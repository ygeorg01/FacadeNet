<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
    <title>FacadeNet</title>
    <meta property="og:description" content="A deep learning approach for
    synthesizing building facade images from diverse viewpoints."/>
    <link rel="stylesheet" type="text/css" href="style.css"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" rel="stylesheet"/>
    <link rel="apple-touch-icon" sizes="180x180" href="gh-page/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="gh-page/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="gh-page/favicon-16x16.png">
<!--    <link rel="manifest" href="gh-page/favicon/site.webmanifest">-->
</head>

<body>
<div class="container">
    <div class="paper-title">
      <h1>FacadeNet: Conditional Facade Synthesis via Selective Editing</h1>
<!--      <h4><a href="https://doi.org/10.1111/cgf.14909">Computer Graphics Forum (Proc. SGP) 2023</a></h4>-->
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-6 text-center"><a href="https://ygeorg01.github.io/">Yiangos Georgiou</a><sup>1</sup></div>
            <div class="col-6 text-center"><a href="https://marios2019.github.io/">Marios Loizou</a><sup>1</sup></div>
            <div class="col-6 text-center"><a href="">Tom Kelly</a><sup>2</sup></div>
            <div class="col-6 text-center"><a href="https://melinos.github.io/">Melinos Averkiou</a><sup>1</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-3 text-center"><sup>1</sup>Univesity of Cyprus/CYENS CoE</div>
            <div class="col-3 text-center"><sup>2</sup>KAUST</div>
        </div>
    </div>

    <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="supp-btn" href="https://arxiv.org/pdf/2311.01240.pdf">
                    <span class="material-icons"> article </span>
                     Paper
                </a>
<!--                <a class="supp-btn" href="assets/CSN_presentation.pdf">-->
<!--                    <span class="material-icons"> slideshow </span>-->
<!--                    PPT at SGP-->
<!--                </a>-->
                <a class="supp-btn" href="gh-page/bib.txt">
                    <span class="material-icons"> format_quote </span>
                      BibTeX
                </a>
                <a class="supp-btn" href="https://github.com/ygeorg01/FacadeNet">
                    <span class="material-icons"> code </span>
                      Code
                </a>
            </div>
        </div>
    <br>
    <section id="teaser">
        <a href="gh-page/teaser_page.png"><img width="100%" src="gh-page/teaser_page.png"></a>
        <br>
        <p class="caption" style="text-align: justify"><em>Left</em>: Utilizing a reference facade image (bottom row, left column)
            and relative camera position information (top row), our method generates novel facades from varied viewpoints, all while
            preserving the reference image’s structure and style (centered columns). Additionally, our approach faithfully reconstructs
            the reference facade (right column). <em>Right</em>: Zoomed facade regions highlight our method’s capacity to modify
            critical facade elements, like windows, across diverse viewpoints (red and orange regions). Furthermore, our approach
            accurately reconstructs (green region) the reference facade (blue region).
        </p>
        <br>
    </section>
        <br>
    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>
        <p>
            We introduce FacadeNet, a deep learning approach for synthesizing building facade images from diverse view-points.
            Our method employs a conditional GAN, taking a single view of a facade along with the desired viewpoint
            information and generates an image of the facade from the distinct viewpoint. To precisely modify view-dependent
            elements like windows and doors while preserving the structure of view-independent components such as walls,
            we introduce a selective editing module. This module leverages image embeddings extracted from a pretrained
            vision transformer. Our experiments demonstrated state-of-the-art performance on building facade generation,
            surpassing alternative methods.
        </p>
        <hr>
        <p align="center">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/J0anjiLNLBo?si=RwgG1WFKFfS1dkGk" title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </p>
    </section>

        <br>
    <section id="qual_results"/>
        <h2>Qualitative Results</h2>
        <hr>
        <h4 align="center">View Interpolation</h4>
        <figure style="width: 100%;">
            <a href="gh-page/qual_eval.png"><img width="100%" src="gh-page/qual_eval.png"></a>
            <p class="caption" style="margin-bottom: 1px; text-align: justify">
                Examples of 5-step image interpolation on the horizontal axis. Given the reference images (left column), we can reconstruct the
novel view from different angles as it is illustrated in the images of columns 2-6.
            </p>
        </figure>
    <h4 align="center">Problematic View Improvment</h4>
        <figure style="width: 100%;">
            <a href="gh-page/view_improvment.png"><img width="100%" src="gh-page/view_improvment.png"></a>
            <p class="caption" style="margin-bottom: 1px; text-align: justify">
                We display examples of problematic facade image improvement. We display pairs of the reference images
                (left) and the θ 0 (center image) reconstruction images(right). We observe that our model can rotate
                the facade to a better view orientation in contrast to the reference while at the same time,
                it achieves a high similarity of style and structure.
            </p>
        </figure>
    </section>

    <section id="evaluation"/>
        <h2>Evaluation</h2>
        <hr>
        <figure style="width: 100%;">
            <a href="gh-page/evaluation.png"><img width="100%" src="gh-page/evaluation.png"></a>
            <p class="caption" style="margin-bottom: 1px; text-align: justify">
                This table presents a comprehensive comparison between our model baseline FacadeNet base, StyleGAN2, Palette,
                3DGP, swapping-autoencoder and FacadeNet. The results clearly demonstrate the superiority of our task-specific
                model across various evaluation criteria, including reconstruction quality, novel view synthesis quality,
                and consistency. To assess the reconstruction image quality, we employ FIDrec, PSNR, and SSIM metrics.
                Regarding novel view image quality we rely on FIDnovel, while we measure the inter-view consistency with
                LPIPS−{alex, vgg} metrics. Our final model FacadeNet outperforms previous approaches by a significant margin.
            </p>
        </figure>
    </section>
    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="https://arxiv.org/pdf/2311.01240.pdf"><img class="paper-thumbnail" src="gh-page/paper_thumbnail.png"></a>
            </div>
            <div style="width: 50%">
                <p><b>FacadeNet: Conditional Facade Synthesis via Selective Editing</b></p>
                <p>Yiangos Georgiou, Marios Loizou, Tom Kelly, Melinos Averkiou</p>

                <div><span class="material-icons"> picture_as_pdf </span><a href="https://arxiv.org/pdf/2311.01240.pdf">PDF</a></div>
<!--                <div><span class="material-icons"> slideshow </span><a href="assets/CSN_presentation.pdf">PPT at SGP</a></div>-->
                <div><span class="material-icons"> format_quote </span><a href="gh-page/bib.txt">BibTeX</a></div>
            </div>
        </div>
    </section>
</div>

</body>
</html>
